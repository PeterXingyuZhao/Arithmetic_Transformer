{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":13859,"status":"ok","timestamp":1769629625321,"user":{"displayName":"Yiqiao Zhong","userId":"06729372927322080600"},"user_tz":360},"id":"aftd1RezTYnF","outputId":"18864fe1-c860-49e2-9669-7622bd7f4c16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/addition\n","configuration_files\t       legacy_code\t   result_analysis.ipynb\n","configurator.py\t\t       llama_adapter.py    result_analysis.py\n","data\t\t\t       llama_tokenizer.py  result_analysis_script\n","data_generate.py\t       main_utilities.py   results\n","data_generation_script\t       model.py\t\t   startHere2.ipynb\n","error_examples\t\t       model_rope.py\t   startHere3.ipynb\n","evaluation.py\t\t       model_t5bias.py\t   startHere.ipynb\n","extra_result_analysis_scripts  __pycache__\t   statistical_measurements.py\n","gsm_test\t\t       README.md\t   train.py\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change directory to your code\n","%cd /content/drive/MyDrive/addition\n","%pwd   # verify youâ€™re in the right place\n","!ls    # should show train.py, 4_operands_addition.txt, etc."]},{"cell_type":"markdown","metadata":{"id":"lbEXozJBCm_X"},"source":["# I. Generate Data (choose one synthetic task)"]},{"cell_type":"markdown","metadata":{"id":"fUKKZHtTI1n3"},"source":["## Addition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbKQwH__Bq4E"},"outputs":[],"source":["!python data_generate.py --task addition --num_operands 4 --experiment_name 4_operands_0_to_999_uniform --train_size 1000000 --test_size 10000 --val_size 10000 --train_eval True --sample-size 10000 --generate_reverse True"]},{"cell_type":"markdown","source":["#### Ablation in Addition (e.g. randomize thousands-place of the output)"],"metadata":{"id":"h95zEWGChhca"}},{"cell_type":"code","source":["!python data_generate.py --task addition --randomize thousands --num_operands 4 --experiment_name 4_operands_0_to_999_output_randomize_thousands --train_size 1000000 --test_size 10000 --val_size 10000 --train_eval True --sample-size 10000 --generate_reverse True\n"],"metadata":{"id":"_JKK2-u_hhAC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Addition with scratchpad (form 1)"],"metadata":{"id":"D0LlhemPvB9K"}},{"cell_type":"code","source":["!python data_generate.py --task addition --reasoning_mode 1 --num_operands 4 --experiment_name 4_operands_0_to_999_uniform_scratchpad1 --train_size 1000000 --test_size 10000 --val_size 10000 --train_eval True --sample-size 10000 --generate_reverse True"],"metadata":{"id":"IJTghfzsvMrw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Addition with scratchpad (form 2)"],"metadata":{"id":"Ny8G_OmQvakc"}},{"cell_type":"code","source":["!python data_generate.py --task addition --reasoning_mode 2 --num_operands 4 --experiment_name 4_operands_0_to_999_uniform_scratchpad2 --train_size 1000000 --test_size 10000 --val_size 10000 --train_eval True --sample-size 10000 --generate_reverse True"],"metadata":{"id":"fH5xyTWpvcOb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBmQXdsiI6YE"},"source":["## Multiplication"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hr3n0w_gIf7i"},"outputs":[],"source":["!python data_generate.py --task multiplication --experiment_name 40_digit_times_1_digit --train_size 1000000 --test_size 10000 --val_size 10000 \\\n","--a_max_digits 40 --b_max_digits 1 --train_eval True --sample-size 10000 --generate_reverse True"]},{"cell_type":"markdown","source":["## Comparison (Balanced data)"],"metadata":{"id":"H8G1HEBCl161"}},{"cell_type":"code","source":["!python data_generate.py --task comparison --experiment_name comparison_bal --train_eval True --sample-size 5000"],"metadata":{"id":"eY6q7tsEl--q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fB5aQJxiI8_h"},"source":["## Sorting (Doubly balanced data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Q7blcAsIVHV"},"outputs":[],"source":["!python data_generate.py --task sorting --experiment_name 4_operands_sorting_doubly_balanced --train_eval True --sample-size 5000"]},{"cell_type":"markdown","metadata":{"id":"8i_CDutAI_fC"},"source":["# II. Let's Start Training!"]},{"cell_type":"markdown","metadata":{"id":"Et7rULRph_Ne"},"source":["#### The .txt file is the configuration file"]},{"cell_type":"markdown","metadata":{"id":"JLXLrm_chIgo"},"source":["## 4 Operands Addition"]},{"cell_type":"markdown","source":["#### Reverse Output format"],"metadata":{"id":"3ItqnAmcm0mN"}},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8S_LDDfvhGLM"},"outputs":[],"source":["!python train.py 4_operands_addition_reversed.txt"]},{"cell_type":"markdown","source":["#### Plain output format"],"metadata":{"id":"7ugltcNHm5QO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0RjN0ldhMGz"},"outputs":[],"source":["!python train.py 4_operands_addition_plain.txt"]},{"cell_type":"markdown","source":["#### Scratchpad Form 1"],"metadata":{"id":"Bos8hxP4nFaL"}},{"cell_type":"code","source":["!python train.py 4_operands_addition_plain_scratchpad1.txt"],"metadata":{"id":"SuDQXox3nMgj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Scratchpad Form 2"],"metadata":{"id":"1kSdQeSdnJaG"}},{"cell_type":"code","source":["!python train.py 4_operands_addition_plain_scratchpad2.txt"],"metadata":{"id":"EWxsTkXVnQ5m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Pythia Finetuning"],"metadata":{"id":"YnwErbJWI0vz"}},{"cell_type":"code","source":["!python train.py 4_operands_addition_plain_pythia.txt"],"metadata":{"id":"K1WAWAfXI5Up","colab":{"base_uri":"https://localhost:8080/"},"outputId":"69c206cc-4993-4363-a28f-559933910d9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using batch preparation method: per_example\n","Loading config file: /content/drive/MyDrive/addition/configuration_files/4_operands_addition_plain_pythia.txt\n","# Pythia-1B Configuration for 4-Operand Addition Task\n","# This config fine-tunes EleutherAI's Pythia-1B model on arithmetic tasks\n","\n","# ===== Model Selection ===== #\n","use_llama = True  # Set to True to use pre-trained model\n","llama_model_name = \"EleutherAI/pythia-1b\"\n","\n","# ===== Evaluation Settings ===== #\n","eval_interval = 2000  # More frequent eval for smaller model\n","eval_iters = 1\n","always_save_checkpoint = True\n","\n","more_early_eval1 = True  # Enable frequent early evaluation\n","early_eval_interval1 = 25  # Evaluate every 25 iterations early on\n","early_eval_border1 = 100  # Until iteration 1000\n","\n","# ===== WandB Logging ===== #\n","wandb_log = True\n","wandb_project = 'addition_pythia'\n","wandb_run_name = '4_operands_addition_plain_pythia_1b'\n","\n","# ===== Model Architecture (Pythia-specific) ===== #\n","block_size = 64  # Larger for BPE efficiency\n","dropout = 0.1  # Light dropout for fine-tuning\n","\n","# ===== Training Configuration ===== #\n","# Pythia-1B is smaller than LLaMA-8B, so we can use larger batch size\n","batch_size = 512  # Can use larger batch than LLaMA (was 64 for LLaMA-8B)\n","gradient_accumulation_steps = 1\n","\n","# ===== Data Format ===== #\n","data_format = 'plain'\n","operator = '+'\n","dataset = 'bal'\n","\n","# ===== Initialization ===== #\n","# Always use 'scratch' when using pre-trained models - loads pre-trained weights then fine-tunes\n","init_from = 'scratch'\n","iter_num = 0\n","# To resume fine-tuning, change to: init_from = 'resume'\n","ckpt_path_name = 'ckpt.pt'\n","\n","# ===== Task Settings ===== #\n","num_digit = 3\n","max_new_tokens = 6  # BPE needs fewer tokens than character-level\n","drop_leading_digit = False\n","zero_pad = False\n","\n","# ===== Learning Rate (Lower for Fine-tuning) ===== #\n","learning_rate = 1e-4  # Lower than custom GPT\n","max_iters =  200000 # Pythia-1B may converge faster than LLaMA-8B\n","lr_decay_iters = 200000\n","beta1 = 0.9\n","beta2 = 0.98 # Higher beta2 for fine-tuning\n","warmup_iters = 500\n","grad_clip = 1.0\n","\n","# ===== Device ===== #\n","device = 'cuda:0'\n","dtype = 'bfloat16'  # Use bfloat16 for efficiency\n","compile = True  # Use PyTorch 2.0 compile\n","\n","# ===== Paths ===== #\n","out_dir = 'results/4_operands_0_to_999_uniform/plain_out_pythia'\n","data_dir = 'data/4_operands_0_to_999_uniform/'\n","\n","# to edit: training data\n","train_data_name = 'train.txt'\n","\n","# to edit: whether do evaluation on training data to see if the model is simply memorizing\n","eval_addition_train = True\n","train_data_test_name = \"train_eval.txt\"\n","\n","# to edit: validation data\n","val_data_name = 'val.txt'\n","eval_addition = True\n","test_file_name = 'test.txt'\n","main_test_name = \"test\"\n","\n","\n","# Mode for evaluation: \"compute_gold\" or \"read_gold_as_str\"\n","mode = \"read_gold_as_str\"\n","\n","# ===== Statistical Measurements ===== #\n","# Disable MI measurement (not yet adapted for BPE tokenization)\n","mi_measurement = False\n","\n","save_final = True\n","use_flash = True  # Will try Flash Attention, fallback to standard if unavailable\n","\n","\n","/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n","  self.setter(val)\n","============================================================\n","Using pre-trained model: EleutherAI/pythia-1b\n","With BPE tokenization\n","============================================================\n","Loading LLaMA tokenizer from: EleutherAI/pythia-1b\n","tokenizer_config.json: 100% 396/396 [00:00<00:00, 3.31MB/s]\n","tokenizer.json: 2.11MB [00:00, 75.0MB/s]\n","special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 966kB/s]\n","Tokenizer does not have a pad token. Defaulting to EOS token: <|endoftext|>\n","Tokenizer initialized: vocab_size=50277, pad_id=0, eos_id=0\n","Tokenizer initialized: vocab_size=50277\n","Using vocabulary size: 50277\n","Collected test files:\n","/content/drive/MyDrive/addition/data/4_operands_0_to_999_uniform/test.txt\n","Using positional encoding: absolute (module: model.py)\n","Loading pre-trained model: EleutherAI/pythia-1b\n","Loading pre-trained model from: EleutherAI/pythia-1b\n","This may take a few minutes...\n","config.json: 100% 569/569 [00:00<00:00, 5.72MB/s]\n","`torch_dtype` is deprecated! Use `dtype` instead!\n","2026-01-28 19:47:40.268842: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2026-01-28 19:47:40.286158: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1769629660.305252    1410 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1769629660.311666    1410 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1769629660.328080    1410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1769629660.328106    1410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1769629660.328110    1410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1769629660.328112    1410 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2026-01-28 19:47:40.332989: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","model.safetensors: 100% 2.09G/2.09G [00:03<00:00, 545MB/s] \n","Flash Attention 2 not available: FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2.\n","Loading with standard attention...\n","âœ“ Loaded with standard attention\n","Gradient checkpointing enabled for memory efficiency\n","Model loaded: 1.01B parameters\n","Vocab size: 50304\n","Pad token ID: 0\n","Starting fresh fine-tuning of EleutherAI/pythia-1b (init_from='scratch')\n","/content/drive/MyDrive/addition/train.py:712: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n","Optimizer: 64 tensors with weight decay, 132 tensors without weight decay\n","Using fused AdamW optimizer\n","compiling the model... (takes a ~minute)\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxzhao468\u001b[0m (\u001b[33mdsharma59-university-of-wisconsin-madison\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£½\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.24.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/addition/results/4_operands_0_to_999_uniform/plain_out_pythia/wandb/run-20260128_194801-ifmwwt7h\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m4_operands_addition_plain_pythia_1b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dsharma59-university-of-wisconsin-madison/addition_pythia\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dsharma59-university-of-wisconsin-madison/addition_pythia/runs/ifmwwt7h\u001b[0m\n","max_new_tokens: 6\n","iter 0: train loss 5.1080, val loss 5.0788\n","Creating new batches\n","Preparing batches from: FILE:/content/drive/MyDrive/addition/data/4_operands_0_to_999_uniform/test.txt\n","Preparing batches for 10000 examples from: FILE:/content/drive/MyDrive/addition/data/4_operands_0_to_999_uniform/test.txt\n","/content/drive/MyDrive/addition/evaluation.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  x = torch.tensor(prompt_ids, dtype=torch.long, device=device)[None, ...]\n","Created 81 batches\n","100% 81/81 [00:11<00:00,  7.08it/s]\n","/content/drive/MyDrive/addition/evaluation.py:689: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  acc_df = pd.concat([acc_df, new_row], ignore_index=True)\n","\n","Test Results:\n","test.txt, 10000 examples: 0/10000  (0.00%)\n","\n","Creating new batches\n","Preparing batches from: FILE:/content/drive/MyDrive/addition/data/4_operands_0_to_999_uniform/train_eval.txt\n","Preparing batches for 10000 examples from: FILE:/content/drive/MyDrive/addition/data/4_operands_0_to_999_uniform/train_eval.txt\n","/content/drive/MyDrive/addition/evaluation.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  x = torch.tensor(prompt_ids, dtype=torch.long, device=device)[None, ...]\n","Created 81 batches\n","100% 81/81 [00:10<00:00,  7.47it/s]\n","iter 25: train loss 3.3258, val loss 3.3078\n","Using precomputed batches\n","100% 81/81 [00:10<00:00,  7.52it/s]\n","\n","Test Results:\n","test.txt, 10000 examples: 8/10000  (0.08%)\n","\n","Using precomputed batches\n","100% 81/81 [00:11<00:00,  7.30it/s]\n","iter 50: train loss 2.7587, val loss 2.7481\n","Using precomputed batches\n","100% 81/81 [00:11<00:00,  6.76it/s]\n","\n","Test Results:\n","test.txt, 10000 examples: 15/10000  (0.15%)\n","\n","Using precomputed batches\n","100% 81/81 [00:10<00:00,  7.41it/s]\n","iter 75: train loss 2.6890, val loss 2.6910\n","Using precomputed batches\n","100% 81/81 [00:11<00:00,  7.28it/s]\n","\n","Test Results:\n","test.txt, 10000 examples: 10/10000  (0.10%)\n","\n","Using precomputed batches\n","100% 81/81 [00:11<00:00,  7.36it/s]\n","iter 100: train loss 2.7008, val loss 2.7028\n","Using precomputed batches\n","100% 81/81 [00:10<00:00,  7.55it/s]\n","\n","Test Results:\n","test.txt, 10000 examples: 9/10000  (0.09%)\n","\n","Using precomputed batches\n","100% 81/81 [00:10<00:00,  7.70it/s]\n","iter 2000: train loss 2.3897, val loss 2.4095\n","Using precomputed batches\n","100% 81/81 [00:10<00:00,  7.93it/s]\n","\n","Test Results:\n","test.txt, 10000 examples: 382/10000  (3.82%)\n","\n"]}]},{"cell_type":"markdown","source":["##"],"metadata":{"id":"u2I7XcQpIyZS"}},{"cell_type":"markdown","metadata":{"id":"QDxgYE9zhL02"},"source":["## Simpel Multiplication"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNcrd8bDha9j"},"outputs":[],"source":["!python train.py 40_1_digits_mul_reversed.txt"]},{"cell_type":"markdown","source":["## Comparison"],"metadata":{"id":"z0dZhitvF1au"}},{"cell_type":"code","source":["!python train.py comparison_bal.txt"],"metadata":{"id":"Hpg2znaxF48M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7UHO3zBc_jY3"},"source":["## Sorting"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"elF2BaDD_izl"},"outputs":[],"source":["!python train.py 4_operands_sorting_doubly_bal.txt"]},{"cell_type":"markdown","metadata":{"id":"hdumgWyAWlt6"},"source":["## Slicing -- Addition"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"pdPiOKoWKw0q"},"outputs":[],"source":["!python train.py slicing_addition_4_operand_plain.txt --batch slicing"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"zqlR08suC-Na"},"outputs":[],"source":["!python train.py slicing_addition_4_operand_reverse.txt --batch slicing"]},{"cell_type":"markdown","metadata":{"id":"30Zi4RZFvtkw"},"source":["## Positional Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"F9dDD_DmvtPz"},"outputs":[],"source":["!python train.py 4_operands_addition_reversed.txt --PE RoPE"]},{"cell_type":"code","source":["!python train.py 4_operands_addition_reversed.txt --PE t5"],"metadata":{"id":"IOqmOrsHZshs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PxLUxyr_u8m-"},"source":["### Greedy Decoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UE5ttFeNvBfb"},"outputs":[],"source":["!python train.py 4_operands_addition_reversed.txt --greedy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4yS-i2zvMLT"},"outputs":[],"source":["!python train.py 4_operands_addition_plain.txt --greedy"]},{"cell_type":"markdown","source":["# III. Result Analysis"],"metadata":{"id":"S_xUM7XznZfi"}},{"cell_type":"markdown","source":["## Addition Task"],"metadata":{"id":"wpid4Duzum1v"}},{"cell_type":"markdown","source":["#### Digitwise Error Rates (4 operands addition)"],"metadata":{"id":"ZLm0jWwznbvH"}},{"cell_type":"code","source":["!python result_analysis_script/digitwise_error.py results/4_operands_0_to_999_uniform/reverse_out_test_garbage/4_operands_0_to_999_uniform_reverse/test_reverse_results.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zuRo6Qlfneh7","executionInfo":{"status":"ok","timestamp":1769626460194,"user_tz":360,"elapsed":5018,"user":{"displayName":"Yiqiao Zhong","userId":"06729372927322080600"}},"outputId":"a566c710-ac5f-4460-c22d-95428f0eacff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/addition/result_analysis_script/digitwise_error.py:109: DtypeWarning: Columns (3,4,5,9,15,19,22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(CSV_PATH)\n","[(0, 'pred_iter_0'), (2000, 'pred_iter_2000'), (4000, 'pred_iter_4000'), (6000, 'pred_iter_6000'), (8000, 'pred_iter_8000'), (10000, 'pred_iter_10000'), (12000, 'pred_iter_12000'), (14000, 'pred_iter_14000'), (16000, 'pred_iter_16000'), (18000, 'pred_iter_18000'), (20000, 'pred_iter_20000'), (22000, 'pred_iter_22000'), (24000, 'pred_iter_24000'), (26000, 'pred_iter_26000'), (28000, 'pred_iter_28000'), (30000, 'pred_iter_30000'), (32000, 'pred_iter_32000'), (34000, 'pred_iter_34000'), (36000, 'pred_iter_36000'), (38000, 'pred_iter_38000'), (40000, 'pred_iter_40000'), (42000, 'pred_iter_42000'), (44000, 'pred_iter_44000'), (46000, 'pred_iter_46000'), (48000, 'pred_iter_48000'), (50000, 'pred_iter_50000'), (52000, 'pred_iter_52000'), (54000, 'pred_iter_54000'), (56000, 'pred_iter_56000'), (58000, 'pred_iter_58000'), (60000, 'pred_iter_60000'), (62000, 'pred_iter_62000'), (64000, 'pred_iter_64000'), (66000, 'pred_iter_66000'), (68000, 'pred_iter_68000'), (70000, 'pred_iter_70000'), (72000, 'pred_iter_72000'), (74000, 'pred_iter_74000'), (76000, 'pred_iter_76000'), (78000, 'pred_iter_78000'), (80000, 'pred_iter_80000'), (82000, 'pred_iter_82000'), (84000, 'pred_iter_84000'), (86000, 'pred_iter_86000'), (88000, 'pred_iter_88000'), (90000, 'pred_iter_90000'), (92000, 'pred_iter_92000'), (94000, 'pred_iter_94000'), (96000, 'pred_iter_96000'), (98000, 'pred_iter_98000'), (100000, 'pred_iter_100000'), (102000, 'pred_iter_102000'), (104000, 'pred_iter_104000'), (106000, 'pred_iter_106000'), (108000, 'pred_iter_108000'), (110000, 'pred_iter_110000'), (112000, 'pred_iter_112000'), (114000, 'pred_iter_114000'), (116000, 'pred_iter_116000'), (118000, 'pred_iter_118000'), (120000, 'pred_iter_120000'), (122000, 'pred_iter_122000')]\n","Figure(1000x600)\n"]}]},{"cell_type":"markdown","source":["#### Fit Normal"],"metadata":{"id":"KKGV9OLkxorj"}},{"cell_type":"code","source":["!python result_analysis_script/fit_normal.py \\\n","  --input results/4_operands_0_to_999_uniform/reverse_out_early_dense_eval/early_dense_eval_for_normal_distr_4_operands_0_to_999_uniform_reverse/test_reverse_results.csv \\\n","  --iter-start 1000 --iter-end 1800 --iter-step 200 \\\n","  --diff-min -800 --diff-max 800\n"],"metadata":{"id":"64BwhPVFxsUv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python result_analysis_script/fit_normal.py \\\n","  --input results/4_operands_0_to_999_uniform/reverse_out/4_operands_0_to_999_uniform_reverse/test_reverse_results.csv \\\n","  --iter-start 8000 --iter-end 12000 --iter-step 2000 \\\n","  --diff-min -100 --diff-max 100\n"],"metadata":{"id":"MAo9jUv32OZb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python result_analysis_script/fit_normal.py \\\n","  --input results/4_operands_0_to_999_uniform/reverse_out/4_operands_0_to_999_uniform_reverse/test_reverse_results.csv \\\n","  --iter-start 60000 --iter-end 64000 --iter-step 2000 \\\n","  --diff-min -20 --diff-max 20\n"],"metadata":{"id":"XDuXMuie2lX6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Mutual Information Plot"],"metadata":{"id":"KeRml6m6u6D9"}},{"cell_type":"code","source":["!python result_analysis_script/plot_mi_metrics.py \\\n","  results/4_operands_0_to_999_uniform/reverse_out_complete_MI_1M_lines/4_operands_0_to_999_uniform_reverse/mi_metrics.csv"],"metadata":{"id":"6uRsOwxFu9ix"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Simple Multiplication Task"],"metadata":{"id":"xO41d50Fuuhb"}},{"cell_type":"markdown","source":["#### Digitwise Error (Simple multiplication, Colormap)"],"metadata":{"id":"_MSBBSKMpivg"}},{"cell_type":"code","source":["!python result_analysis_script/mul_digitwise_error_colormap.py results/40_digit_times_1_digit/reverse_out/40_digit_times_1_digit/test_reverse_results.csv --max_steps 3000"],"metadata":{"id":"Ubs8HAlept0H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Comparison Task\n","\n","\n"],"metadata":{"id":"BFe2zjmUXmBG"}},{"cell_type":"markdown","source":["#### Comparison Error Rate (Contrast Pairs)"],"metadata":{"id":"fTNrvoFH1Gns"}},{"cell_type":"code","source":["!python result_analysis_script/comparison_error_rate.py \\\n","  results/comparison_bal/comparison_bal_1/thousands_diff_only_results.csv \\\n","  results/comparison_bal/comparison_bal_1/hundreds_diff_only_results.csv \\\n","  results/comparison_bal/comparison_bal_1/tens_diff_only_results.csv \\\n","  results/comparison_bal/comparison_bal_1/units_diff_only_results.csv \\\n","  --output_file_name contrast_pair_error_rate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvPu4BRg1hzv","executionInfo":{"status":"ok","timestamp":1769390017898,"user_tz":360,"elapsed":10936,"user":{"displayName":"Yiqiao Zhong","userId":"06729372927322080600"}},"outputId":"c9bb6e08-9a6b-4bda-ce24-d767709cba20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved plot to results/comparison_bal/comparison_bal_1/contrast_pair_error_rate\n"]}]},{"cell_type":"markdown","source":["## Sorting Task"],"metadata":{"id":"zRHI0Sm3uyhG"}},{"cell_type":"markdown","source":["#### Sorting Subskill from 10% to 90% Range"],"metadata":{"id":"nvWbmBTe_eo2"}},{"cell_type":"code","source":["!python result_analysis_script/sorting_acc_10_90_range.py \\\n","  --csv \\\n","    results/4_operands_sorting_doubly_balanced/conflicting_same_control_exp_correction/4_operands_sorting_doubly_balanced_conflicting_same_correction/test_results.csv \\\n","    results/4_operands_sorting_doubly_balanced/conflicting_same_control_exp_correction/4_operands_sorting_doubly_balanced_conflicting_same_correction/digitwise_random_results.csv \\\n","    results/4_operands_sorting_doubly_balanced/conflicting_same_control_exp_correction/4_operands_sorting_doubly_balanced_conflicting_same_correction/digitwise_thousand_results.csv \\\n","    results/4_operands_sorting_doubly_balanced/conflicting_same_control_exp_correction/4_operands_sorting_doubly_balanced_conflicting_same_correction/digitwise_hundred_results.csv \\\n","    results/4_operands_sorting_doubly_balanced/conflicting_same_control_exp_correction/4_operands_sorting_doubly_balanced_conflicting_same_correction/digitwise_ten_results.csv \\\n","  --positions 1,2,3,4 \\\n","  --mode length first second third fourth\n"],"metadata":{"id":"4i7Dx_c2_mC2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Sorting Mixing Error"],"metadata":{"id":"7Pn0bJmxsooN"}},{"cell_type":"code","source":["!python result_analysis_script/mixing_error.py results/4_operands_sorting_doubly_balanced/conflicting_same_control_exp_correction_v2/4_operands_sorting_doubly_balanced_conflicting_same_correction_v2/1_3_same_2_4_agreeing_v2_results.csv\n"],"metadata":{"id":"SSM9s55usiis"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# IV. NanoGPT Scaling"],"metadata":{"id":"PNjTQtpaVazE"}},{"cell_type":"markdown","source":["#### 20M Parameters"],"metadata":{"id":"q0eO2DJ3VgL-"}},{"cell_type":"code","source":["!python train.py 20M_4_operands_addition_reversed.txt"],"metadata":{"id":"XTfVndPoVacJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 100M Parameters"],"metadata":{"id":"NC8I2HzzWDO2"}},{"cell_type":"code","source":["!python train.py 100M_4_operands_addition_reversed.txt"],"metadata":{"id":"qzOQSKlWWFdC"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}